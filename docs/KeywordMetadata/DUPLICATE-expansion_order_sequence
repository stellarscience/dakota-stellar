Blurb:: The (initial) order of a polynomial expansion

Description::

When the expansion_order for a a polynomial chaos expansion is
specified, the coefficients may be computed by integration based on
random samples or by regression using either random or sub-sampled
tensor product quadrature points.

Multidimensional integration by Latin hypercube sampling
   (specified with \c expansion_samples). In this case, the
   expansion order \e p cannot be inferred from the numerical
   integration specification and it is necessary to provide an
   \c expansion_order to specify \e p for a total-order expansion.

Linear regression (specified with either \c collocation_points or
   \c collocation_ratio). A total-order expansion is used and must
   be specified using \c expansion_order as described in the
   previous option. <!-- Given \e p or \e N, the total number of
   collocation points (including any sample reuse) must be at least
   \e N, and an oversampling is generally advisable. To more easily
   satisfy this requirement (i.e., to avoid requiring the user to
   calculate \e N from \e n and \e p), --> To avoid requiring the 
   user to calculate \e N from \e n and \e p), the \c collocation_ratio 
   allows for specification of a constant factor applied to \e
   N (e.g., \c collocation_ratio = \c 2. produces samples = \e 2N).
   In addition, the default linear relationship with \e N can be
   overridden using a real-valued exponent specified using \c
   ratio_order. In this case, the number of samples becomes
   \f$cN^o\f$ where \f$c\f$ is the \c collocation_ratio and \f$o\f$
   is the \c ratio_order. The \c use_derivatives flag informs the
   regression approach to include derivative matching equations
   (limited to gradients at present) in the least squares solutions,
   enabling the use of fewer collocation points for a given
   expansion order and dimension (number of points required becomes
   \f$\frac{cN^o}{n+1}\f$). When admissible, a constrained least
   squares approach is employed in which response values are first
   reproduced exactly and error in reproducing response derivatives
   is minimized. Two collocation grid options are supported: the
   default is Latin hypercube sampling ("point collocation"), and an
   alternate approach of "probabilistic collocation" is also
   available through inclusion of the \c tensor_grid keyword. In
   this alternate case, the collocation grid is defined using a
   subset of tensor-product quadrature points: the order of the 
   tensor-product grid is selected as one more than the expansion
   order in each dimension (to avoid sampling at roots of the basis 
   polynomials) and then the tensor multi-index is uniformly sampled
   to generate a non-repeated subset of tensor quadrature points.
   <!-- the order of the tensor-product grid is the minimum required
   to meet or exceed the point requirement, and then this set of
   points is filtered down to the requirement based on the subset of
   points having highest product integration weight. In our experience,
   the alternate probabilistic collocation approach using a structured
   grid tends to suffer from ill-conditioning more quickly than the
   default point collocation approach using an unstructured grid. -->

If \c collocation_points or \c collocation_ratio is specified, the PCE
coefficients will be determined by regression.
If no regression
specification is provided, appropriate defaults are defined.
Specifically SVD-based least-squares will be used for solving
over-determined systems and under-determined systems will be solved
using LASSO. For the situation when the number of function values is
smaller than the number of terms in a PCE, but the total number of
samples including gradient values is greater than the number of terms,
the resulting over-determined system will be solved using equality
constrained least squares. Technical information on the various
methods listed below can be found in the Linear regression section of
the Theory Manual. Some of the regression methods (OMP, LASSO, and
LARS) are able to produce a set of possible PCE coefficient vectors
(see the Linear regression section in the Theory Manual). If cross
validation is inactive, then only one solution, consistent with the \c
noise_tolerance, will be returned. If cross validation is active,
%Dakota will choose between possible coefficient vectors found
internally by the regression method across the set of expansion orders
(1,...,\c expansion_order) and the set of specified noise tolerances and
return the one with the lowest cross validation error indicator.

<b> Usage Tips </b>

For most use cases, this keyword will specify a single integer order.
In more advanced UQ studies with hierarchical models, the list of
integers can apply to different models and/or model levels

Topics::
Examples::
Theory::
Faq::
See_Also::	
